num_classes: &num_classes 81
runtime:
  random_seed: 40244023
  task_names: det
  rank_init: true

flip: &flip
 type: flip
 kwargs:
   flip_p: 0.5

range_crop: &crop
  type: range_crop
  kwargs:
    scales: [400, 500, 600]
    crop_size: [384, 600]

resize: &train_resize
 type: keep_ar_resize
 kwargs:
   scales: [640, 672, 704, 736, 768, 800, 864, 896]
   max_size: 1500
   separate_wh: True

test_resize: &test_resize
 type: keep_ar_resize
 kwargs:
   scales: [800]
   max_size: 1333
   separate_wh: True

to_tensor: &to_tensor
  type: to_tensor

normalize: &normalize
 type: normalize
 kwargs:
   mean: [0.485, 0.456, 0.406] # ImageNet pretrained statics
   std: [0.229, 0.224, 0.225]

dataset: # Required.
  train:
    dataset:
      type: coco
      kwargs:
        meta_file: /mnt/lustre/share/DSK/datasets/mscoco2017/annotations/instances_train2017.json
        image_reader:
          type: fs_opencv
          kwargs:
            image_dir: /mnt/lustre/share/DSK/datasets/mscoco2017/train2017
            color_mode: RGB
        transformer: [*flip, *crop, *train_resize, *to_tensor, *normalize]
  test:
    dataset:
      type: coco
      kwargs:
        meta_file: /mnt/lustre/share/DSK/datasets/mscoco2017/annotations/instances_val2017.json
        image_reader:
          type: fs_opencv
          kwargs:
            image_dir: /mnt/lustre/share/DSK/datasets/mscoco2017/val2017
            color_mode: RGB
        transformer: [*test_resize, *to_tensor, *normalize]
        evaluator:
          type: COCO               # choices = {'COCO', 'VOC', 'MR'}
          kwargs:
            gt_file: /mnt/lustre/share/DSK/datasets/mscoco2017/annotations/instances_val2017.json
            iou_types: [bbox]
  batch_sampler:
    type: aspect_ratio_group
    kwargs:
      sampler:
        type: dist
        kwargs: {}
      batch_size: 2
      aspect_grouping: [1,]
  dataloader:
    type: base
    kwargs:
      num_workers: 4
      alignment: 32
      worker_init: true
      pin_memory: True

trainer: # Required.
  max_epoch: 36             # total epochs for the training
  save_freq: 3
  test_freq: 2
  optimizer:                 # optimizer = SGD(params,lr=0.001,momentum=0.9,weight_decay=0.0001)
    type: AdamW
    kwargs:
      lr: 0.0000025 # 0.00004
      weight_decay: 0.0001
  lr_scheduler:              # lr_scheduler = MultStepLR(optimizer, milestones=[9,14],gamma=0.1)
    warmup_epochs: 0        # set to be 0 to disable warmup. When warmup,  target_lr = init_lr * total_batch_size
    warmup_type: linear
    warmup_iter: 1000
    warmup_ratio: 0.01     # warmup init lr =  warmup_ratio * base_lr
    type: MultiStepLR
    kwargs:
      milestones: [28, 34]   # [8, 11] epochs to decay lr
      gamma: 0.1             # decay rate

saver: # Required.
  save_dir: checkpoints/onenet_ret50    # dir to save checkpoints
  pretrain_model: /mnt/lustre/share/DSK/model_zoo/pytorch/imagenet/resnet50-19c8e357.pth
  results_dir: results_dir/onenet_ret50  # dir to save detection results. i.e., bboxes, masks, keypoints
  auto_resume: false

hooks:
  - type: grad_clipper
    kwargs:
      mode: pre_defined
      max_norm: 1  

net:
  - name: backbone              # backbone = resnet50(frozen_layers, out_layers, out_strides)
    type: resnet50
    kwargs:
      frozen_layers: [0,1]     # layer0...1 is fixed
      out_layers: [2,3,4]       # layer1...4, commonly named Conv2...5
      out_strides: [8,16,32]    # tell the strides of output features
      normalize:
        type: freeze_bn
      initializer:
        method: msra
  - name: neck
    prev: backbone
    type: FPN
    kwargs:
      outplanes: 256
      start_level: 3
      num_level: 5                # if num_level>len(backbone.out_layers), additional conv with be stacked.
      out_strides: [8,16,32,64,128] # strides of output features. aka., anchor strides for roi_head
      downsample: conv            # method to downsample, for FPN, it's pool, for RetienaNet, it's conv
      upsample: nearest           # method to interp, nearest or bilinear
      initializer:
        method: xavier
  - name: roi_head
    prev: neck
    type: RetinaSubNet
    kwargs:
      feat_planes: 256        # channels of intermediate conv
      num_classes: *num_classes         # number of classes including backgroudn. for rpn, it's 2; for RetinaNet, it's 81
      initializer:
        method: normal
        std: 0.01
      init_prior: 0.01
      num_anchors: 9
      class_activation: sigmoid
  - name: post_process
    prev: roi_head
    type: onenet_post
    kwargs:
      num_classes: *num_classes  # number of classes including backgroudn. for rpn, it's 2; for RetinaNet, it's 81
      net_type: retina
      l1_weight: 5.0
      cfg:
        cls_loss:
          type: sigmoid_focal_loss
          kwargs:
            num_classes: *num_classes
            alpha: 0.25
            gamma: 2.0
            loss_weight: 2.0
        loc_loss:
          type: iou_loss
          kwargs:
            loss_type: giou
            loss_weight: 2.0
        anchor_generator:
          type: hand_craft
          kwargs:
            anchor_ratios: [0.5,1,2]  # anchor strides are provided as feature strides by feature extractor
            anchor_scales: [4, 5.0396842, 6.34960421] # scale of anchors relative to feature map
        roi_supervisor:
          type: onenet
          kwargs:
            matcher:
              type: onenet
              kwargs:
                cost_cls: 2.0
                cost_l1: 5.0
                cost_giou: 2.0    # Required if provide ignore_regions
        roi_predictor:
          type: onenet
          kwargs:
            topk_boxes: 100
            min_size: 0.0
