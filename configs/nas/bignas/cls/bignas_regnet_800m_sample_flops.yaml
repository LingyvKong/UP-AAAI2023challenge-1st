num_classes: &num_classes 1000

runtime:
  rank_init: True
  runner:
      type: bignas


random_augmentation: &random_augmentation
  type: torch_random_augmentationIncre
  kwargs:
    n: 2  # number of augmentation operations
    m: 9  # magnitude of each operation
    magnitude_std: 0.5  # standard deviation of magnitude

center_crop: &center_crop
  type: torch_center_crop
  kwargs:
    size: 224

torch_size: &torch_resize
  type: torch_resize
  kwargs:
    size: 256


random_resized_crop: &random_resized_crop
 type: torch_random_resized_crop
 kwargs:
   size: 224
   scale: [0.08, 1]

random_horizontal_flip: &random_horizontal_flip
 type: torch_random_horizontal_flip

pil_color_jitter: &pil_color_jitter
 type: torch_color_jitter
 kwargs:
  brightness: 0.2
  contrast: 0.2
  saturation: 0.2
  hue: 0.1


color_jitter: &color_jitter
  type: color_jitter
  kwargs:
    brightness: 32
    contrast: [0.5, 1.5]
    saturation: [0.5, 1.5]
    hue: 18

to_tensor: &to_tensor
  type: to_tensor

normalize: &normalize
 type: normalize
 kwargs:
   mean: [0.485, 0.456, 0.406] # ImageNet pretrained statics
   std: [0.229, 0.224, 0.225]

dataset: # Required.
  train:
    dataset:
      type: cls
      kwargs:
        meta_file: /mnt/lustre/share/images/meta/train.txt
        image_reader:
           type: fs_pillow
           kwargs:
             image_dir: /mnt/lustre/share/images/train
             color_mode: RGB
        transformer: [*random_resized_crop, *random_horizontal_flip, *to_tensor, *normalize]
    batch_sampler:
        type: base
        kwargs:
          sampler:
            type: dist
            kwargs: {}
          batch_size: 32
    dataloader:
        type: cls_base
        kwargs:
          num_workers: 4
          pin_memory: True
  test:
    dataset:
      type: cls
      kwargs:
        meta_file: /mnt/lustre/share/images/meta/val.txt
        image_reader:
          type: fs_pillow
          kwargs:
            image_dir: /mnt/lustre/share/images/val
            color_mode: RGB
        transformer: [*torch_resize, *center_crop, *to_tensor, *normalize]
        evaluator:
          type: imagenet               # choices = {'COCO', 'VOC', 'MR'}
          kwargs:
             topk: [1, 5]

    batch_sampler:
      type: base
      kwargs:
        sampler:
          type: dist
          kwargs: {}
        batch_size: 32
    dataloader:
      type: cls_base
      kwargs:
        num_workers: 4
        pin_memory: False


trainer:  # Required.
  max_epoch: 300              # total epochs for the training
  test_freq: 10
  save_freq: 10
  optimizer:                 # optimizer = SGD(params,lr=0.001,momentum=0.9,weight_decay=0.0001)
    type: SGD
    kwargs:
      lr: 0.00125
      momentum: 0.9
      weight_decay: 0.0001
  lr_scheduler:              # lr_scheduler = MultStepLR(optimizer, milestones=[9,14],gamma=0.1)
    warmup_epochs: 1         # set to be 0 to disable warmup. When warmup,  target_lr = init_lr * total_batch_size
    type: MultiStepLR
    warmup_type: linear
    kwargs:
      milestones: [210, 270]     # epochs to decay lr
      gamma: 0.1             # decay rate

saver: # Required.
  save_dir: checkpoints/ret18     # dir to save checkpoints
  results_dir: results_dir/ret18  # dir to save detection results. i.e., bboxes, masks, keypoints
  # auto_resume: True  # find last checkpoint from save_dir and resume from it automatically
                     # this option has the highest priority (auto_resume > opts > resume_model > pretrain_model)

bignas:
    train:
        sample_subnet_num: 1
        sample_strategy: ['max', 'random', 'random', 'min']
        valid_before_train: False
    data:
        share_interpolation: False
        interpolation_type: bicubic
        image_size_list: [[1, 3, 224, 224]]
        calib_meta_file: /mnt/lustre/share/shenmingzhu/calib_coco/coco_2048_coco_format.json
        metric1: bbox.AP
        metric2: bbox.AP.5
    subnet:
        image_size: [1, 3, 224, 224]
        flops_range: ['600M', '1000M']
        baseline_flops: 800M
        subnet_count: 50

hooks:
  - type: auto_checkpoint

net:
  - name: backbone              # backbone = resnet50(frozen_layers, out_layers, out_strides)
    type: big_regnet
    kwargs:
      task: detection
      frozen_layers: []     # layer0...1 is fixed
      out_layers: [4]       # layer1...4, commonly named Conv2...5
      out_strides: [32]    # tell the strides of output features
      normalize:
          type: dynamic_solo_bn
      out_channel:
          space:
              min: [32, 48, 96, 224, 576] # origin [32, 64, 128, 288, 672]
              max: [32, 80, 160, 320, 768]
              stride: [16, 16, 32, 32, 32]
          sample_strategy: stage_wise
      kernel_size: [3, 3, 3, 3, 3]
      expand_ratio: [1, 1, 1, 1, 1]
      group_width: [16, 16, 16, 16, 16]
      depth:
          space:
              min: [1, 1, 2, 5, 4] # origin [1, 1, 3, 7, 5]
              max: [1, 1, 4, 9, 6]
              stride: [1, 1, 1, 1, 1]
          sample_strategy: stage_wise_depth
  - name: head
    type: BigClsHead
    kwargs:
       num_classes: *num_classes
       in_plane: 768
       input_feature_idx: -1
  - name: post_process
    type: base_cls_postprocess
    kwargs:
       cls_loss:
         type: label_smooth_ce
         kwargs:
            smooth_ratio: 0.1
            num_classes: *num_classes
